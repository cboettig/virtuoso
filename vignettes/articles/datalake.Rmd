---
title: "The Data Lake: Schema on Read"
author: "Carl Boettiger"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{datalake}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE
)
```



```{r}
library(virtuoso)
library(rdftools) # for write_nquads.  Needs: install_github("cboettig/rdftools")
library(dplyr)

```

# Tabular Data

```{r}
library(nycflights13)
```

We start up our Virtuoso server, wait for it to come up, and then connect:

```{r install}
vos_start()
```

```{r}
con <- vos_connect()
```


We can represent any data as RDF with a little care.  For instance, consider the `nycflights13` data. First, we must represent any primary or foreign keys in any table as URIs, indicated by a prefix, and not by bare strings:

```{r as_uri}
uri_flights <- flights %>% 
  mutate(tailnum = paste0("planes:", tailnum),
         carrier = paste0("airlines:", carrier))
```

We write the `data.frame`s out as nquads.  Recall that each cell of a `data.frame` can be represented as a triple, in which the column is the predicate, the primary key (or row number) the subject, and the cell value the object.  We turn column names and primary keys into URIs using a prefix based on the table name. 

```{r}
write_nquads(airlines,  "airlines.nq", key = "carrier", prefix = "airlines:")
write_nquads(planes,  "planes.nq", key = "tailnum", prefix = "planes:")
write_nquads(uri_flights,  "flights.nq", prefix = "flights:")
```

We're ready to import all these triples.  This may take a few minutes:

```{r}
system.time(
  vos_import(con, c("flights.nq", "planes.nq", "airlines.nq"))
)
```


The data from all three tables is now reduced into a single triplestore graph, one triple for each data point. Rather than joining tables, we can write SPARQL query that names the columns we want.



```{r}
query <- 
'SELECT  ?carrier ?name ?manufacturer ?model ?dep_delay
WHERE {
?flight <flights:tailnum>  ?tailnum .
?flight <flights:carrier>  ?carrier .
?flight <flights:dep_delay>  ?dep_delay .
?tailnum <planes:manufacturer> ?manufacturer .
?tailnum <planes:model> ?model .
?carrier <airlines:name> ?name
}'

system.time(
df <- vos_query(con, query)
)

head(df)
```


# List Data




Transform JSON (or list data) into triples.  In this case, we have a large JSON blob (or R list)
containing metadata on all rOpenSci packages:

```{r}
x <- jsonlite::read_json("https://raw.githubusercontent.com/ropensci/roregistry/master/registry.json")
write_nquads(x, "ropensci.nq.gz", prefix = "http://schema.org/")
```


And bulk-import

```{r}
vos_import(con, "ropensci.nq.gz")
```

Find all packages where "Carl Boettiger" is an "author", and return:
package name, license, and co-author surnames: 

```{r}
query <-
"PREFIX schema: <http://schema.org/>
SELECT DISTINCT ?package ?license ?coauthor
 WHERE {
 ?s schema:identifier ?package ;
    schema:author ?author ;
    schema:license ?license ;
    schema:name ?name ;
    schema:author ?coauth .
 ?author schema:givenName 'Carl' .
 ?author schema:familyName 'Boettiger' .
 ?coauth schema:familyName ?coauthor
}"

vos_query(con, query) %>% 
as_tibble() %>% 
mutate(license = basename(license)) # Tidy up URIs into names
```


```{r}
query <-
  rdftools:::sparql_op() %>%
  rdftools:::select("identifier", "license", prefix = "http://schema.org/") %>%
  rdftools:::filter(author.familyName == "Boettiger",
         author.givenName == "Carl",
        prefix = "http://schema.org/") %>%
  rdftools:::sparql_build()

vos_query(con, query)

```




```{r include=FALSE}
unlink("flights.nq")
unlink("planes.nq")
unlink("airlines.nq")
unlink("ropensci.nq")
```
